{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn,optim\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    preprocess=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "    return (datasets.MNIST(root='./dataset',train=True,transform=preprocess,download=True))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data=data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader=torch.utils.data.DataLoader(mnist_data,batch_size=100,shuffle=True)\n",
    "num_batches=len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator Net\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator,self).__init__()\n",
    "        n_features=784 #28*28 is the input size for each image\n",
    "        n_out=1 #we need a binary decision here: real or fake\n",
    "        self.lin0=nn.Linear(n_features,1024)\n",
    "        self.lin1=nn.Linear(1024,512)\n",
    "        self.lin2=nn.Linear(512,256)\n",
    "        self.out=nn.Linear(256,n_out)\n",
    "        self.dropout=nn.Dropout(p=0.3)\n",
    "        self.leaky=nn.LeakyReLU(0.2)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.dropout(self.leaky(self.lin0(x)))\n",
    "        x=self.dropout(self.leaky(self.lin1(x)))\n",
    "        x=self.dropout(self.leaky(self.lin2(x)))\n",
    "        x=self.sigmoid(self.out(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object creation\n",
    "disc=Discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional functionality\n",
    "def image_to_vec(image):\n",
    "    return image.view(image.size(0),784)\n",
    "\n",
    "def vec_to_image(vector):\n",
    "    return vector.view(vector.size(0),1,28,28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator net\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        n_features=100\n",
    "        n_out=784\n",
    "        self.lin0=nn.Linear(n_features,256)\n",
    "        self.lin1=nn.Linear(256,512)\n",
    "        self.lin2=nn.Linear(512,1024)\n",
    "        self.out=nn.Linear(1024,n_out)\n",
    "        self.leaky=nn.LeakyReLU(0.2)\n",
    "        self.tanh=nn.Tanh()\n",
    "\n",
    "        def forward(self,x):\n",
    "            x=self.leaky(self.lin0(x))\n",
    "            x=self.leaky(self.lin1(x))\n",
    "            x=self.leaky(self.lin2(x))\n",
    "            x=self.tanh(self.out(x))\n",
    "            return x\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functionality for random noise\n",
    "def noise(size):\n",
    "    n=torch.randn(size,100)#100 for the batch size\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizers\n",
    "disc_optimizer=optim.Adam(disc.parameters(),lr=0.0002)\n",
    "gen_optimizer=optim.Adam(gen.parameters(),lr=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=nn.BCELoss()#resembles the loss we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more functionality for image targets\n",
    "def ones_target(size):\n",
    "    data=torch.ones(size,1)\n",
    "    return data\n",
    "\n",
    "def zeros_target(size):\n",
    "    data=torch.zeros(size,1)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_disc(opt,real_data,fake_data):\n",
    "    N=real_data.size(0)\n",
    "    opt.zero_grad()#reset gradients\n",
    "    \n",
    "    pred_real=disc(real_data)\n",
    "    error_real=loss(pred_real,ones_target(N))\n",
    "    error_real.backward()\n",
    "    \n",
    "    pred_fake=disc(fake_data)\n",
    "    error_fake=loss(pred_fake,zeros_target(N))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    opt.step()\n",
    "    \n",
    "    return error_real+error_fake,pred_real,pred_fake\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gen(opt,fake_data):\n",
    "    N=fake_data.size(0)\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    pred=disc(fake_data)\n",
    "    error=loss(pred,ones_target(N))\n",
    "    error.backward()\n",
    "    opt.step()\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples=16\n",
    "test_noise=noise(num_test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "logger = Logger(model_name='VGAN', data_name='MNIST')\n",
    "\n",
    "num_epochs=200\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch,(real_batch,_) in enumerate(dataloader):\n",
    "        N=real_batch.size(0)\n",
    "        \n",
    "        real_data=image_to_vec(real_batch)\n",
    "        \n",
    "        fake_data=gen(noise(N)).detach()\n",
    "        d_error,d_pred_real,d_pred_fake=train_disc(d_opt,real_data,fake_data)\n",
    "        \n",
    "        fake_data=gen(noise(N))\n",
    "        g_error=train_gen(_opt,fake_data)\n",
    "        \n",
    "        logger.log(d_error, g_error, epoch, n_batch, num_batches)\n",
    "        \n",
    "        if (n_batch)%10==0: \n",
    "            test_images=vec_to_image(generator(test_noise))\n",
    "            test_images=test_images.data\n",
    "        \n",
    "        logger.log_images(test_images, num_test_samples, epoch, n_batch, num_batches);\n",
    "        logger.display_status(epoch, num_epochs, n_batch, num_batches,d_error, g_error, d_pred_real, d_pred_fake)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
